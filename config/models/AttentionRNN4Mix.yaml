name: AttentionRNN4Mix

model:
  hidden_size: 256
  num_layers: 1
  linear_size: [256, 128]
  dropout: 0.5
  emb_trainable: true
  emb_size: 300

train:
  input_opts:
    return_attn: true
  output_opts:
    pass_attn: true
